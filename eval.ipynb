{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74c0a3c-93e9-4e1e-83f0-0656375eb3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n",
      "env: HF_HOME=/mnt/LLM\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "%env HF_HOME=/mnt/LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14425290-6de8-46ef-ba0b-5b783fb2f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def exec_command(command, env=None) -> str:\n",
    "    if env is None:\n",
    "        env = os.environ.copy()\n",
    "    \n",
    "    process = subprocess.run(command, capture_output=True, env=env)\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        return process.stdout.decode() + '\\n' + process.stderr.decode()\n",
    "    \n",
    "    raise Exception('command {} failed\\nstdout:\\n{}\\nstderr:\\n{}'.format(\n",
    "        command,\n",
    "        process.stdout.decode(),\n",
    "        process.stderr.decode(),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d630de7-bc46-4140-9d69-b018a07d10ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ISTA-DASLab/Meta-Llama-3-8B-AQLM-PV-2Bit-1x16',\n",
       " 'config': {'model': 'hf',\n",
       "  'model_args': 'pretrained=ISTA-DASLab/Meta-Llama-3-8B-AQLM-PV-2Bit-1x16',\n",
       "  'model_num_parameters': 2042171392,\n",
       "  'model_dtype': 'torch.float16',\n",
       "  'model_revision': 'main',\n",
       "  'model_sha': 'ad1d994ac589738b729ece3c334edd6765bed365',\n",
       "  'batch_size': '16',\n",
       "  'batch_sizes': [],\n",
       "  'device': None,\n",
       "  'use_cache': None,\n",
       "  'limit': None,\n",
       "  'bootstrap_iters': 100000,\n",
       "  'gen_kwargs': None,\n",
       "  'random_seed': 0,\n",
       "  'numpy_seed': 1234,\n",
       "  'torch_seed': 1234,\n",
       "  'fewshot_seed': 1234},\n",
       " 'configs': {'mmlu_continuation_high_school_government_and_politics': {'task': 'mmlu_continuation_high_school_government_and_politics',\n",
       "   'group': 'mmlu_continuation_social_sciences',\n",
       "   'dataset_path': 'hails/mmlu_no_train',\n",
       "   'dataset_name': 'high_school_government_and_politics',\n",
       "   'dataset_kwargs': {'trust_remote_code': True},\n",
       "   'test_split': 'test',\n",
       "   'fewshot_split': 'dev',\n",
       "   'doc_to_text': 'Question: {{question.strip()}}\\nAnswer:',\n",
       "   'doc_to_target': '{{answer}}',\n",
       "   'doc_to_choice': '{{choices}}',\n",
       "   'description': 'The following are questions (with answers) about high school government and politics.\\n\\n',\n",
       "   'target_delimiter': ' ',\n",
       "   'fewshot_delimiter': '\\n\\n',\n",
       "   'fewshot_config': {'sampler': 'first_n'},\n",
       "   'num_fewshot': 1,\n",
       "   'output_type': 'multiple_choice',\n",
       "   'repeats': 1,\n",
       "   'should_decontaminate': False,\n",
       "   'metadata': {'version': 0.0}}},\n",
       " 'results': {'mmlu_continuation_high_school_government_and_politics': {'acc,none': 0.5181347150259067,\n",
       "   'acc_stderr,none': 0.03606065001832916,\n",
       "   'acc_norm,none': 0.5492227979274611,\n",
       "   'acc_norm_stderr,none': 0.03590910952235521,\n",
       "   'alias': 'mmlu_continuation_high_school_government_and_politics'}},\n",
       " 'model_size': 4084350976}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "def trim_lm_eval_output(output):\n",
    "    return {\n",
    "        'model_name': output['model_name'],\n",
    "        'config': output['config'],\n",
    "        'configs': output['configs'],\n",
    "        'results': output['results'],\n",
    "    }\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    output = 0\n",
    "    for param in model.parameters():\n",
    "        output += param.nelement() * param.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        output += buffer.nelement() * buffer.element_size()\n",
    "    return output\n",
    "\n",
    "\n",
    "def run_lm_eval(model_name, task, num_fewshot=1, batch_size=16):\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        cmd = ['lm_eval']\n",
    "    \n",
    "        cmd.extend(['--model', 'hf'])\n",
    "        cmd.extend(['--model_args', f'pretrained={model_name}'])\n",
    "        cmd.extend(['--tasks', task])\n",
    "        cmd.extend(['--batch_size', str(batch_size)])\n",
    "        cmd.extend(['--output_path', tmpdirname])\n",
    "        cmd.extend(['--num_fewshot', str(num_fewshot)])\n",
    "    \n",
    "        exec_command(cmd)\n",
    "    \n",
    "        def get_ony_dir_entry(path):\n",
    "            entries = os.listdir(path)\n",
    "            assert len(entries) == 1\n",
    "            return entries[0]\n",
    "    \n",
    "        path = tmpdirname\n",
    "        path = os.path.join(path, get_ony_dir_entry(path))\n",
    "        path = os.path.join(path, get_ony_dir_entry(path))\n",
    "    \n",
    "        with open(path, 'r') as file:\n",
    "            output = trim_lm_eval_output(json.load(file))\n",
    "\n",
    "        output['model_size'] = get_model_size(AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True, low_cpu_mem_usage=True,\n",
    "        ))\n",
    "        \n",
    "        return output\n",
    "\n",
    "run_lm_eval('ISTA-DASLab/Meta-Llama-3-8B-AQLM-PV-2Bit-1x16', 'mmlu_continuation_high_school_government_and_politics')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
