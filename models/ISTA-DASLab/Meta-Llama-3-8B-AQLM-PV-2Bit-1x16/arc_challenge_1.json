{
    "model_name": "ISTA-DASLab/Meta-Llama-3-8B-AQLM-PV-2Bit-1x16",
    "config": {
        "model": "hf",
        "model_args": "pretrained=ISTA-DASLab/Meta-Llama-3-8B-AQLM-PV-2Bit-1x16",
        "model_num_parameters": 2042171392,
        "model_dtype": "torch.float16",
        "model_revision": "main",
        "model_sha": "ad1d994ac589738b729ece3c334edd6765bed365",
        "batch_size": "16",
        "batch_sizes": [],
        "device": null,
        "use_cache": null,
        "limit": null,
        "bootstrap_iters": 100000,
        "gen_kwargs": null,
        "random_seed": 0,
        "numpy_seed": 1234,
        "torch_seed": 1234,
        "fewshot_seed": 1234
    },
    "configs": {
        "arc_challenge": {
            "task": "arc_challenge",
            "group": [
                "ai2_arc"
            ],
            "dataset_path": "allenai/ai2_arc",
            "dataset_name": "ARC-Challenge",
            "training_split": "train",
            "validation_split": "validation",
            "test_split": "test",
            "doc_to_text": "Question: {{question}}\nAnswer:",
            "doc_to_target": "{{choices.label.index(answerKey)}}",
            "doc_to_choice": "{{choices.text}}",
            "description": "",
            "target_delimiter": " ",
            "fewshot_delimiter": "\n\n",
            "num_fewshot": 1,
            "metric_list": [
                {
                    "metric": "acc",
                    "aggregation": "mean",
                    "higher_is_better": true
                },
                {
                    "metric": "acc_norm",
                    "aggregation": "mean",
                    "higher_is_better": true
                }
            ],
            "output_type": "multiple_choice",
            "repeats": 1,
            "should_decontaminate": true,
            "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
            "metadata": {
                "version": 1.0
            }
        }
    },
    "results": {
        "arc_challenge": {
            "acc,none": 0.4522184300341297,
            "acc_stderr,none": 0.014544519880633825,
            "acc_norm,none": 0.4931740614334471,
            "acc_norm_stderr,none": 0.014610029151379957,
            "alias": "arc_challenge"
        }
    },
    "model_size": 4084350976
}